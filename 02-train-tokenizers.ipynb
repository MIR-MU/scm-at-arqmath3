{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c382c1-7d3a-4039-9197-ee8556a3afb6",
   "metadata": {},
   "source": [
    "# Train tokenizer\n",
    "\n",
    "Before training language models, we need to learn how to tokenize text and math. We are going to use [pre-trained `roberta-base` tokenizer][1] and extend it with `[MATH]`, `[/MATH]` special tokens and math-specific tokens.\n",
    "\n",
    " [1]: https://huggingface.co/roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e4a728-741a-4f6d-a7c8-955e49ced6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker.apollo.fi.muni.cz\n"
     ]
    }
   ],
   "source": [
    "! hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c338c-5fc9-46d1-ad27-a63fadea6173",
   "metadata": {},
   "source": [
    "## The LaTeX format\n",
    "\n",
    "First, we will train a tokenizer on LaTeX math to learn math-specific tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf1d5bd-5690-4bc4-9735-12e50c43de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, normalizers, pre_tokenizers\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "try:\n",
    "    latex_tokenizer = Tokenizer.from_file('tokenizer-latex.json')\n",
    "except:\n",
    "    latex_model = BPE(unk_token='[UNK]')\n",
    "    latex_tokenizer = Tokenizer(latex_model)\n",
    "    latex_tokenizer.pre_tokenizer = pre_tokenizers.WhitespaceSplit()\n",
    "    latex_tokenizer.normalizer = normalizers.Sequence([normalizers.Strip()])\n",
    "    latex_tokenizer_trainer = BpeTrainer(special_tokens=['[UNK]'])\n",
    "    latex_tokenizer.train(['dataset-latex.txt'], latex_tokenizer_trainer)\n",
    "    _ = latex_tokenizer.save('tokenizer-latex.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c39daf-1466-4c24-8439-ed4651c3e6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F(x)', '&=\\\\int', '^a', '_b', '\\\\frac{1}{3}', 'x^3']\n"
     ]
    }
   ],
   "source": [
    "print(latex_tokenizer.encode(r'F(x)&=\\int^a_b\\frac{1}{3}x^3').tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15532785-9bdc-4fcb-a25b-314da06e4b3c",
   "metadata": {},
   "source": [
    "## The text + LaTeX format\n",
    "\n",
    "Next, we will extend pre-trained `roberta-base` tokenizer with `[MATH]`, `[/MATH]` special tokens and LaTeX math tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd65d96-fdd1-4b4f-b8fa-8cb7dfaf1a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "try:\n",
    "    text_latex_tokenizer = AutoTokenizer.from_pretrained('./roberta-base-text+latex/')\n",
    "except:\n",
    "    text_latex_tokenizer = AutoTokenizer.from_pretrained('roberta-base', add_prefix_space=True)\n",
    "    text_latex_tokenizer.add_special_tokens({'additional_special_tokens': [' [MATH] ', ' [/MATH]']})\n",
    "    text_latex_tokenizer.add_tokens(list(latex_tokenizer.get_vocab()))\n",
    "    _ = text_latex_tokenizer.save_pretrained('./roberta-base-text+latex/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349b05d1-0624-454f-84fc-be95864309d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ĠThe', 'Ġproposed', 'Ġmodel', ' [MATH] ', 'F(x)', '&=\\\\int', '^a', '_b', '\\\\frac{1}{3}', 'x^3', ' [/MATH]', 'Ġwas', 'Ġtrained', 'Ġusing', 'ĠAD', 'AM', 'Ġopt', 'imiz', 'Ġer']\n"
     ]
    }
   ],
   "source": [
    "print(text_latex_tokenizer.tokenize(\n",
    "    r'The proposed model [MATH] F(x)&=\\int^a_b\\frac{1}{3}x^3 [/MATH] was trained using ADAM optimizer'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
