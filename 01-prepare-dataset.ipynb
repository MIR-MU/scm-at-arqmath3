{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8105520d-9d6c-4bd8-b2b1-e41a330bb6b7",
   "metadata": {},
   "source": [
    "# Prepare training dataset\n",
    "\n",
    "To train tokenizer and language models, we will prepare a datasets from [ArXMLiv 2020][1] and [Math StackExchange][2] datasets.\n",
    "\n",
    " [1]: https://sigmathling.kwarc.info/resources/arxmliv-dataset-2020/\n",
    " [2]: https://www.cs.rit.edu/~dprl/ARQMath/arqmath-resources.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32dd4523-8c12-483f-a432-39622c34b68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker.apollo.fi.muni.cz\n"
     ]
    }
   ],
   "source": [
    "! hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a3c53-fec1-471d-a9a3-33528e268b13",
   "metadata": {},
   "source": [
    "## The text + LaTeX format\n",
    "\n",
    "As our primary representation, we use text and LaTeX separated by special `[MATH]` and `[/MATH]` tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60467d2b-b6ac-409b-9158-75a0e6f8be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! make dataset-text+latex.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffa8605-2b3f-443e-80af-3d93b21489a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 1008 1011 4.3G Apr 28 02:18 dataset-text+latex.txt\n"
     ]
    }
   ],
   "source": [
    "%ls -lh dataset-text+latex.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf96978a-e8cc-4b2b-adfe-043b703238b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That means that [MATH] \\delta [/MATH] should retain the signal under convolution. In the frequency domain the spectrum [MATH] \\Delta:=\\sF(\\delta) [/MATH] of [MATH] \\delta [/MATH] should retain the spectrum [MATH] X [/MATH] of the signal [MATH] x [/MATH] under multiplication. If our signal space [MATH] \\sS [/MATH] contains signals [MATH] x [/MATH] whose spectra [MATH] X [/MATH] have unbounded support this implies that the spectrum of [MATH] \\Delta [/MATH] must be the unit function, i.e., [MATH] \\Delta(\\omega)=1 [/MATH] for all [MATH] \\omega\\in\\nR [/MATH] . But, if there exists an upper limit frequency [MATH] \\omega_\\rmu>0 [/MATH] such that the spectra [MATH] X [/MATH] for all signals [MATH] x\\in\\sS [/MATH] are zero outside of [MATH] [-\\omega_\\rmu,\\omega_\\rmu] [/MATH] then [MATH] \\Delta(\\omega) [/MATH] must only be 1 for [MATH] \\omega\\in[-\\omega_\\rmu,\\omega_\\rmu] [/MATH] . We can construct an appropriate generator for our base as inverse Fourier transformed of \\begin{align} \\Delta(\\omega) &= \\begin{cases} 1 &\\text{ for } \\omega \\in [-\\omega_\\rmu,\\omega_\\rmu]\\\\ 0 &\\text{ else } \\end{cases} \\end{align}\n",
      "We consider a two dimensional channel. The diffusion of particles takes place in this confined environment. We are looking for a reduced description in a one dimensional space (the coordinate along the direction of the channel), including effects of the hard-core interaction. We consider an external potential [MATH] U(x)\n",
      "So in your case, [MATH] \\;P := q\\; [/MATH] and [MATH] \\;Q := \\lnot r \\land \\lnot p\\; [/MATH] , and therefore \"for [MATH] \\;q\\; [/MATH] , it is necessary but not sufficient that [MATH] \\;\\lnot r \\land \\lnot p\\; [/MATH] \" translates to [MATH] \\;\\lnot q \\land \\lnot r \\land \\lnot p\\; [/MATH] , so that is your answer.\n"
     ]
    }
   ],
   "source": [
    "! head -3 dataset-text+latex.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6021394-abfe-49e1-935f-5deefe940ea6",
   "metadata": {},
   "source": [
    "## The LaTeX format\n",
    "\n",
    "To train a tokenizer just for math, we also have a separate dataset with just LaTeX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d52467-0ebc-4026-abad-32cb5d86ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! make dataset-latex.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4868409-ccce-4635-8410-a3bc61942711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 1008 1011 702M Apr 28 01:33 dataset-latex.txt\n"
     ]
    }
   ],
   "source": [
    "%ls -lh dataset-latex.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ba4e68-7bf7-4156-a104-798eac46dced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x) = m(E \\cap (-\\infty,x])\n",
      "\\displaystyle=|\\psi(\\boldsymbol{R})|^{2}.\n",
      "\\|f-\\Gamma_n\\|_\\infty \\le \\epsilon\n"
     ]
    }
   ],
   "source": [
    "! head -3 dataset-latex.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8028ea-551b-48ff-93c9-19b3fde07edf",
   "metadata": {},
   "source": [
    "## The Tangent-L format\n",
    "\n",
    "To train a tokenizer just for math, we also have a separate dataset with just the format used by [the Tangent-L search engine from UWaterloo][1].\n",
    "\n",
    " [1]: http://ceur-ws.org/Vol-2936/paper-05.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a30b5f00-2ce9-4471-96ab-c7e76047a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! make dataset-tangentl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde7e049-43f4-44f0-b19d-d1eaa157da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 1008 1011 24G Apr 28 06:40 dataset-tangentl.txt\n"
     ]
    }
   ],
   "source": [
    "%ls -lh dataset-tangentl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482e3d3c-a6ff-49c9-87fc-0b8514809478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#(start)# #(v!p,[n,b],-)# #(v!p,[n,b])# #(v!p,m!()1x1,n,-)# #(v!p,m!()1x1,n)# #(m!()1x1,[n,w],n)# #(m!()1x1,[n,w])# #(m!()1x1,=,n,n)# #(m!()1x1,=,n)# #(=,n!2,n,nn)# #(=,n!2,n)# #(n!2,v!p,n,nnn)# #(n!2,v!p,n)# #(v!p,m!()1x1,n,nnnn)# #(v!p,m!()1x1,n)# #(m!()1x1,v!g,w,nnnnn)# #(m!()1x1,v!g,w)# #(v!g,!0,5n1w)# #(v!g,!0)# #(m!()1x1,v!g,w,n)# #(m!()1x1,v!g,w)# #(v!g,!0,nw)# #(v!g,!0)# #{v!g,nnnnw,w,n}# #{v!g,nnnnw,w}# #{m!()1x1,nnnn,n}# #{m!()1x1,nnnn}# #(v!p,n!2,b,-)# #(v!p,n!2,b)# #(n!2,!0,b)# #(n!2,!0)# #{n!2,nnn,b,-}# #{n!2,nnn,b}# #{v!p,nnnn,-}# #{v!p,nnnn}# #(end)#\n",
      "#(start)# #(v!φ,[n,b],-)# #(v!φ,[n,b])# #(v!φ,m!()1x1,n,-)# #(v!φ,m!()1x1,n)# #(m!()1x1,[n,w],n)# #(m!()1x1,[n,w])# #(m!()1x1,f!,n,n)# #(m!()1x1,f!,n)# #(f!,[n,o,u],nn)# #(f!,[n,o,u])# #(f!,=,n,nn)# #(f!,=,n)# #(=,v!φ,n,nnn)# #(=,v!φ,n)# #(v!φ,[n,a,b],nnnn)# #(v!φ,[n,a,b])# #(v!φ,v!e,n,nnnn)# #(v!φ,v!e,n)# #(v!e,[n,a],nnnnn)# #(v!e,[n,a])# #(v!e,×,n,nnnnn)# #(v!e,×,n)# #(×,m!{2x2,n,6n)# #(×,m!{2x2,n)# #(m!{2x2,v!f,w,7n)# #(m!{2x2,v!f,w)# #(v!f,[b,e],7n1w)# #(v!f,[b,e])# #(v!f,v!gzk,b,7n1w)# #(v!f,v!gzk,b)# #(v!gzk,!0,7n1w1b)# #(v!gzk,!0)# #(v!f,v!for,e,7n1w)# #(v!f,v!for,e)# #(v!for,[n,e],7n1w1e)# #(v!for,[n,e])# #(v!for,v!protons,n,7n1w1e)# #(v!for,v!protons,n)# #(v!protons,!0,7n1w1e1n)# #(v!protons,!0)# #(v!for,v!f,e,7n1w1e)# #(v!for,v!f,e)# #(v!f,[b,e],7n1w2e)# #(v!f,[b,e])# #(v!f,v!nuc,b,7n1w2e)# #(v!f,v!nuc,b)# #(v!nuc,!0,7n1w2e1b)# #(v!nuc,!0)# #(v!f,v!for,e,7n1w2e)# #(v!f,v!for,e)# #(v!for,v!nuclei,n,7n1w3e)# #(v!for,v!nuclei,n)# #(v!nuclei,!0,7n1w3e1n)# #(v!nuclei,!0)# #{v!for,ee,7n1w1e}# #{v!for,ee}# #{v!f,ee,7n1w}# #{v!f,ee}# #(v!e,-,a,nnnnn)# #(v!e,-,a)# #(-,v!γ,n,5n1a)# #(-,v!γ,n)# #(v!γ,v!eg,b,5n1a1n)# #(v!γ,v!eg,b)# #(v!eg,!0,5n1a1n1b)# #(v!eg,!0)# #(v!φ,w!,a,nnnn)# #(v!φ,w!,a)# #(w!,!0,nnnna)# #(w!,!0)# #(v!φ,n!0,b,nnnn)# #(v!φ,n!0,b)# #(n!0,v!eg,n,nnnnb)# #(n!0,v!eg,n)# #(v!eg,!0,4n1b1n)# #(v!eg,!0)# #{v!eg,nanb,bn,nnnn}# #{v!eg,nanb,bn}# #(f!,v!d,o,nn)# #(f!,v!d,o)# #(v!d,v!φ,n,nno)# #(v!d,v!φ,n)# #(v!φ,v!eg,b,nnon)# #(v!φ,v!eg,b)# #(v!eg,!0,nnonb)# #(v!eg,!0)# #{v!eg,3n1a1n1b,onb,nn}# #{v!eg,3n1a1n1b,onb}# #{v!eg,nnbn,onb,nn}# #{v!eg,nnbn,onb}# #{v!φ,nn,on,nn}# #{v!φ,nn,on}# #(f!,v!d,u,nn)# #(f!,v!d,u)# #(v!d,v!e,n,nnu)# #(v!d,v!e,n)# #(v!e,!0,nnun)# #(v!e,!0)# #{v!e,nnn,un,nn}# #{v!e,nnn,un}# #{v!d,o,u,nn}# #{v!d,o,u}# #(m!()1x1,v!e,w,n)# #(m!()1x1,v!e,w)# #(v!e,!0,nw)# #(v!e,!0)# #{v!e,nnnn,w,n}# #{v!e,nnnn,w}# #{v!e,nun,w,n}# #{v!e,nun,w}# #(v!φ,v!eg,b,-)# #(v!φ,v!eg,b)# #(v!eg,!0,b)# #(v!eg,!0)# #{v!eg,5n1a1n1b,b,-}# #{v!eg,5n1a1n1b,b}# #{v!eg,4n1b1n,b,-}# #{v!eg,4n1b1n,b}# #{v!eg,nnonb,b,-}# #{v!eg,nnonb,b}# #{v!φ,nnnn,-}# #{v!φ,nnnn}# #{v!φ,nnon,-}# #{v!φ,nnon}# #(end)#\n",
      "#(start)# #(v!q,m!()1x1,n,-)# #(v!q,m!()1x1,n)# #(m!()1x1,[n,w],n)# #(m!()1x1,[n,w])# #(m!()1x1,=,n,n)# #(m!()1x1,=,n)# #(=,-,n,nn)# #(=,-,n)# #(-,v!q,n,nnn)# #(-,v!q,n)# #(v!q,m!()1x1,n,nnnn)# #(v!q,m!()1x1,n)# #(m!()1x1,v!x,w,nnnnn)# #(m!()1x1,v!x,w)# #(v!x,!0,5n1w)# #(v!x,!0)# #(m!()1x1,-,w,n)# #(m!()1x1,-,w)# #(-,v!x,n,nw)# #(-,v!x,n)# #(v!x,!0,nwn)# #(v!x,!0)# #{v!x,nnnnw,wn,n}# #{v!x,nnnnw,wn}# #{-,nn,w,n}# #{-,nn,w}# #{m!()1x1,nnnn,n}# #{m!()1x1,nnnn}# #{v!q,nnnn,-}# #{v!q,nnnn}# #(end)#\n"
     ]
    }
   ],
   "source": [
    "! head -3 dataset-tangentl.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
