{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8105520d-9d6c-4bd8-b2b1-e41a330bb6b7",
   "metadata": {},
   "source": [
    "# Prepare dataset\n",
    "\n",
    "To train tokenizer and language models, we will prepare a datasets from [ArXMLiv 2020][1] and [Math StackExchange][2] datasets.\n",
    "\n",
    " [1]: https://sigmathling.kwarc.info/resources/arxmliv-dataset-2020/\n",
    " [2]: https://www.cs.rit.edu/~dprl/ARQMath/arqmath-resources.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32dd4523-8c12-483f-a432-39622c34b68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mir\n"
     ]
    }
   ],
   "source": [
    "! hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a3c53-fec1-471d-a9a3-33528e268b13",
   "metadata": {},
   "source": [
    "## The text + LaTeX format\n",
    "\n",
    "As our primary representation, we use text and LaTeX separated by special `[MATH]` and `[/MATH]` tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60467d2b-b6ac-409b-9158-75a0e6f8be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! make dataset-text+latex.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffa8605-2b3f-443e-80af-3d93b21489a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 novotny novotny 52G May  5 03:52 dataset-text+latex.txt\n"
     ]
    }
   ],
   "source": [
    "%ls -lh dataset-text+latex.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf96978a-e8cc-4b2b-adfe-043b703238b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The study was conducted based on a within-subjects design. Participants were shown five scenes with a virtual character walking in different environments. Participants performed [MATH] 10 [/MATH] trials per scene, corresponding to [MATH] 10 [/MATH] virtual characters with varying levels of predicted dominance. The order of the scenes and the dominance levels of the virtual characters were counterbalanced. Participants performed the study using HTC Vive HMD. Participants could look around in the virtual environment by rotating their heads and could also walk in the tracking space, but there was no interaction with the virtual characters (Figure 1 (top)).\n",
      "The security properties of the longest chain protocol has been intensely studied in recent years. The strong security properties have been demonstrated in increasing sophistication (both network models as well as tightness of security threshold): the pioneering work of [12] on the round by round network model has been extended to discrete and finely partitioned network model in [19] and to a continuous time network model in [21]. The tightness of the security threshold has been improved to the best possible in [10]. Despite this wealth of technical background, the checkpointed longest chain protocol has seemingly subtle differences with the vanilla longest chain protocol, but impact the analysis significantly. We discuss two of these issues next.\n",
      "Raman infrared spectroscopy, as a versatile method for structural characterization, has been widely used to study the electronic and vibrational properties in materials. The Raman spectrum is directly related to the lattice dynamics of materials, including phonon dispersion curves, phonon density of states, and infrared and Raman active modes. These properties can be predicted by first-principles calculations using the optimized atomic structures. Single-layer phosphorene has a point group symmetry of [MATH] C_{2h} [/MATH] , which also determines the infrared and Raman activity of each mode. Infrared-active modes create a dipole moment while Raman active modes induce polarization or quadruple moment in the lattice.\n"
     ]
    }
   ],
   "source": [
    "! head -3 dataset-text+latex.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94d360-080d-425a-a58f-217741a8dbcb",
   "metadata": {},
   "source": [
    "For validation of our language models, we use the `error` subset (documents with recoverable errors) of [ArXMLiv 2020][1].\n",
    "\n",
    " [1]: https://sigmathling.kwarc.info/resources/arxmliv-dataset-2020/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f64f1af8-c106-438e-a889-e214f989bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! make dataset-text+latex-validation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "965e57c9-253e-49f1-bbbe-64c0be8514a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 novotny novotny 22G May  5 07:25 dataset-text+latex-validation.txt\n"
     ]
    }
   ],
   "source": [
    "%ls -lh dataset-text+latex-validation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8286285-0092-494c-b238-67394c4dc7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following our conventions in [GHK13], let [MATH] \\mathfrak{T} [/MATH] be the infinite oriented rooted tree with [MATH] |I_{\\mathrm{uf}}| [/MATH] outgoing edges from each vertex, labelled by the elements of [MATH] I_{\\mathrm{uf}} [/MATH] . Let [MATH] v [/MATH] be the root of the tree. Attach some choice of initial seed [MATH] {\\bf s}\\in[{\\bf s}] [/MATH] to the vertex [MATH] v [/MATH] . (We write [MATH] \\mathfrak{T}_{{\\bf s}} [/MATH] if we want to record this choice of initial seed.) Now each simple path starting at [MATH] v [/MATH] determines a sequence of mutations, just mutating at the label attached to the edge. In this way we attach a seed to each vertex of [MATH] \\mathfrak{T} [/MATH] . We write the seed attached to a vertex [MATH] w [/MATH] as [MATH] {\\bf s}_{w} [/MATH] , and write [MATH] T_{N^{\\circ},{\\bf s}_{w}},T_{M,{\\bf s}_{w}} [/MATH] etc. for the corresponding tori. Mutations define birational maps between these tori, and the associated Fock-Goncharov [MATH] \\mathcal{A} [/MATH] , [MATH] \\mathcal{X} [/MATH] cluster varieties are defined by (A.3) [MATH] \\mathcal{A}_{\\Gamma}=\\bigcup_{w\\in\\mathfrak{T}}T_{N^{\\circ},{{\\bf s}_{w}}},% \\quad\\quad\\mathcal{X}_{\\Gamma}=\\bigcup_{w\\in\\mathfrak{T}}T_{M,{\\bf s}_{w}}. [/MATH] This parameterization of torus charts is very redundant, with infinitely many copies of the same chart appearing. In particular, given a vertex [MATH] w [/MATH] of [MATH] \\mathfrak{T} [/MATH] , one can consider the subtree [MATH] \\mathfrak{T}_{w} [/MATH] rooted at [MATH] w [/MATH] , with initial seed [MATH] {\\bf s}_{w} [/MATH] . This tree can similarly be used to define [MATH] \\mathcal{A}_{\\Gamma} [/MATH] , and the obvious inclusion between these two versions of [MATH] \\mathcal{A}_{\\Gamma} [/MATH] is in fact an isomorphism, as can be easily checked.\n",
      "For an endomorphism [MATH] f [/MATH] of an object [MATH] X [/MATH] of a pivotal category [MATH] \\mathcal{C} [/MATH] , one defines the left and right traces [MATH] \\mathrm{tr}_{l}(f),\\mathrm{tr}_{r}(f)\\in\\mathrm{End}_{\\mathcal{C}}(\\mathbb{1}) [/MATH] by [MATH] \\mathrm{tr}_{l}(f)=\\mathrm{ev}_{X}(\\mathrm{id}_{{X}^{*}}\\otimes f)\\widetilde{% \\mathrm{coev}}_{X}\\quad{\\text{and}}\\quad\\mathrm{tr}_{r}(f)=\\widetilde{\\mathrm{% ev}}_{X}(f\\otimes\\mathrm{id}_{{X}^{*}})\\mathrm{coev}_{X}. [/MATH] They satisfy [MATH] \\mathrm{tr}_{l}(gh)=\\mathrm{tr}_{l}(hg) [/MATH] and [MATH] \\mathrm{tr}_{r}(gh)=\\mathrm{tr}_{r}(hg) [/MATH] for any morphisms [MATH] g\\colon X\\to Y [/MATH] and [MATH] h\\colon Y\\to X [/MATH] in [MATH] \\mathcal{C} [/MATH] . Also we have [MATH] \\mathrm{tr}_{l}(f)=\\mathrm{tr}_{r}({f}^{*})=\\mathrm{tr}_{l}(f^{**}) [/MATH] for any endomorphism [MATH] f [/MATH] in [MATH] \\mathcal{C} [/MATH] . If (1) [MATH] \\alpha\\otimes\\mathrm{id}_{X}=\\mathrm{id}_{X}\\otimes\\alpha\\quad\\text{for all $% \\alpha\\in\\mathrm{End}_{\\mathcal{C}}(\\mathbb{1})$ and $X$ in $\\mathcal{C}$,} [/MATH] then [MATH] \\mathrm{tr}_{l},\\mathrm{tr}_{r} [/MATH] are [MATH] \\otimes [/MATH] -multiplicative, that is, [MATH] \\mathrm{tr}_{l}(f\\otimes g)=\\mathrm{tr}_{l}(f)\\,\\mathrm{tr}_{l}(g) [/MATH] and [MATH] \\mathrm{tr}_{r}(f\\otimes g)=\\mathrm{tr}_{r}(f)\\,\\mathrm{tr}_{r}(g) [/MATH] for all endomorphisms [MATH] f,g [/MATH] in [MATH] \\mathcal{C} [/MATH] .\n",
      "The remainder of this Dissertation then describes various parallels and differences between Schensted Insertion and another natural extension of Single Row Bumping called Patience Sorting. We first describe Patience Sorting in Section 1.1.3. Further background material on permutation patterns is then given in Section 1.1.4. We then provide a summary of the main results of this Dissertation in Section 1.2.\n"
     ]
    }
   ],
   "source": [
    "! head -3 dataset-text+latex-validation.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d42859-e253-4e14-9caa-bccc1ebb6545",
   "metadata": {},
   "source": [
    "## The text format\n",
    "\n",
    "To train a tokenizer just for text, we also have a separate dataset with just text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6600ec86-8fa2-466b-9322-26d1af188404",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! make dataset-text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9d83a5b-a453-4c73-b3a3-075326e89077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 novotny novotny 32G May  5 08:49 dataset-text.txt\n"
     ]
    }
   ],
   "source": [
    "%ls -lh dataset-text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc3cf00-8ca3-44e1-9c4f-b206161b0e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the re-acceleration model, the radio halo switches off with the radio halo CRe cooling timescale of about 0.1 Gyr the moment the re-acceleration stops to operate, irrespective if there is CRe transport from the outside or not.\n",
      " Let be the Euclidean unit disk Let and define . Let be open and nonempty. Then determines and , up to the gauge transformations, in the convex hull of .\n",
      " In real space the simplest estimator for the full box is given by Mo and White (1996) (33) where is the mean number of neighbour halos in a shell at distance with width around a halo at , and is the mean number density of halos in the simulation at a given time, such that gives the mean number of neighbour halos if the halos were evenly distributed. Therefore estimates the excess probability to find a halo within an interval away from another halo. We determine as , where is the total number of halos in the box and is the number of all halo pairings with distance . In practice we calculate (34) where is the distance between halo and halo . In order to estimate the error bars and the covariance matrix of , we instead calculate (35) where is the mean number of neighbour halos in a shell at distance around a halo in the subsample , which is obtained be removing the subbox . Therefore is the excess probability to find a halo at distance away from another halo within the subsample. We determine as , where is the total number of halos in the subsample and is the number of all halo pairings with distance , with at least one partner lying in (36) The correlation function is then given by (37) with covariance matrix (38) and error bar (39) We choose and cover 100 -bins. Fig. 13 shows the halo correlation for 7 mass bins at . We indicate with the dotted line the nonlinear regime. For the largest mass bin corresponding to large galaxy clusters, a drop in the correlation function for smaller than twice the virial radius is due to halo exclusion arising in a friend-of-friend halo finder that was used in HR2.\n"
     ]
    }
   ],
   "source": [
    "! head -3 dataset-text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6021394-abfe-49e1-935f-5deefe940ea6",
   "metadata": {},
   "source": [
    "## The LaTeX format\n",
    "\n",
    "To train a tokenizer just for math, we also have a separate dataset with just LaTeX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6d52467-0ebc-4026-abad-32cb5d86ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! make dataset-latex.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4868409-ccce-4635-8410-a3bc61942711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 novotny novotny 11G May  5 03:36 dataset-latex.txt\n"
     ]
    }
   ],
   "source": [
    "%ls -lh dataset-latex.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ba4e68-7bf7-4156-a104-798eac46dced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\displaystyle=E(F_{n}(L(a),L(F_{n}(b,c))))\n",
      "\\int_{\\hat{S}_{\\rm men}}\\!\\!\\!\\!\\!\\!dA\\;\\Pi_{1}u_{2}\\sim 2\\pi\\gamma r_{0}% \\varepsilon_{\\Pi}u(d)+\\Pi(d)\\left[2\\int_{{S}_{\\rm men,2}}\\!\\!\\!\\!\\!\\!dA\\;u_{2}% -\\frac{1}{2}\\pi r_{0}^{3}\\varepsilon_{\\Pi}+\\pi r_{0}^{2}\\langle u_{2}\\rangle_{% 2}\\right],\n",
      "\\left|t\\right|>\\left|\\tau\\right|\n"
     ]
    }
   ],
   "source": [
    "! head -3 dataset-latex.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8028ea-551b-48ff-93c9-19b3fde07edf",
   "metadata": {},
   "source": [
    "## The Tangent-L format\n",
    "\n",
    "To train a tokenizer just for math, we also have a separate dataset with just the format used by [the Tangent-L search engine from UWaterloo][1].\n",
    "\n",
    " [1]: http://ceur-ws.org/Vol-2936/paper-05.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a30b5f00-2ce9-4471-96ab-c7e76047a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! make dataset-tangentl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fde7e049-43f4-44f0-b19d-d1eaa157da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 novotny novotny 24G Apr 28 08:40 dataset-tangentl.txt\n"
     ]
    }
   ],
   "source": [
    "%ls -lh dataset-tangentl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "482e3d3c-a6ff-49c9-87fc-0b8514809478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#(start)# #(v!p,[n,b],-)# #(v!p,[n,b])# #(v!p,m!()1x1,n,-)# #(v!p,m!()1x1,n)# #(m!()1x1,[n,w],n)# #(m!()1x1,[n,w])# #(m!()1x1,=,n,n)# #(m!()1x1,=,n)# #(=,n!2,n,nn)# #(=,n!2,n)# #(n!2,v!p,n,nnn)# #(n!2,v!p,n)# #(v!p,m!()1x1,n,nnnn)# #(v!p,m!()1x1,n)# #(m!()1x1,v!g,w,nnnnn)# #(m!()1x1,v!g,w)# #(v!g,!0,5n1w)# #(v!g,!0)# #(m!()1x1,v!g,w,n)# #(m!()1x1,v!g,w)# #(v!g,!0,nw)# #(v!g,!0)# #{v!g,nnnnw,w,n}# #{v!g,nnnnw,w}# #{m!()1x1,nnnn,n}# #{m!()1x1,nnnn}# #(v!p,n!2,b,-)# #(v!p,n!2,b)# #(n!2,!0,b)# #(n!2,!0)# #{n!2,nnn,b,-}# #{n!2,nnn,b}# #{v!p,nnnn,-}# #{v!p,nnnn}# #(end)#\n",
      "#(start)# #(v!φ,[n,b],-)# #(v!φ,[n,b])# #(v!φ,m!()1x1,n,-)# #(v!φ,m!()1x1,n)# #(m!()1x1,[n,w],n)# #(m!()1x1,[n,w])# #(m!()1x1,f!,n,n)# #(m!()1x1,f!,n)# #(f!,[n,o,u],nn)# #(f!,[n,o,u])# #(f!,=,n,nn)# #(f!,=,n)# #(=,v!φ,n,nnn)# #(=,v!φ,n)# #(v!φ,[n,a,b],nnnn)# #(v!φ,[n,a,b])# #(v!φ,v!e,n,nnnn)# #(v!φ,v!e,n)# #(v!e,[n,a],nnnnn)# #(v!e,[n,a])# #(v!e,×,n,nnnnn)# #(v!e,×,n)# #(×,m!{2x2,n,6n)# #(×,m!{2x2,n)# #(m!{2x2,v!f,w,7n)# #(m!{2x2,v!f,w)# #(v!f,[b,e],7n1w)# #(v!f,[b,e])# #(v!f,v!gzk,b,7n1w)# #(v!f,v!gzk,b)# #(v!gzk,!0,7n1w1b)# #(v!gzk,!0)# #(v!f,v!for,e,7n1w)# #(v!f,v!for,e)# #(v!for,[n,e],7n1w1e)# #(v!for,[n,e])# #(v!for,v!protons,n,7n1w1e)# #(v!for,v!protons,n)# #(v!protons,!0,7n1w1e1n)# #(v!protons,!0)# #(v!for,v!f,e,7n1w1e)# #(v!for,v!f,e)# #(v!f,[b,e],7n1w2e)# #(v!f,[b,e])# #(v!f,v!nuc,b,7n1w2e)# #(v!f,v!nuc,b)# #(v!nuc,!0,7n1w2e1b)# #(v!nuc,!0)# #(v!f,v!for,e,7n1w2e)# #(v!f,v!for,e)# #(v!for,v!nuclei,n,7n1w3e)# #(v!for,v!nuclei,n)# #(v!nuclei,!0,7n1w3e1n)# #(v!nuclei,!0)# #{v!for,ee,7n1w1e}# #{v!for,ee}# #{v!f,ee,7n1w}# #{v!f,ee}# #(v!e,-,a,nnnnn)# #(v!e,-,a)# #(-,v!γ,n,5n1a)# #(-,v!γ,n)# #(v!γ,v!eg,b,5n1a1n)# #(v!γ,v!eg,b)# #(v!eg,!0,5n1a1n1b)# #(v!eg,!0)# #(v!φ,w!,a,nnnn)# #(v!φ,w!,a)# #(w!,!0,nnnna)# #(w!,!0)# #(v!φ,n!0,b,nnnn)# #(v!φ,n!0,b)# #(n!0,v!eg,n,nnnnb)# #(n!0,v!eg,n)# #(v!eg,!0,4n1b1n)# #(v!eg,!0)# #{v!eg,nanb,bn,nnnn}# #{v!eg,nanb,bn}# #(f!,v!d,o,nn)# #(f!,v!d,o)# #(v!d,v!φ,n,nno)# #(v!d,v!φ,n)# #(v!φ,v!eg,b,nnon)# #(v!φ,v!eg,b)# #(v!eg,!0,nnonb)# #(v!eg,!0)# #{v!eg,3n1a1n1b,onb,nn}# #{v!eg,3n1a1n1b,onb}# #{v!eg,nnbn,onb,nn}# #{v!eg,nnbn,onb}# #{v!φ,nn,on,nn}# #{v!φ,nn,on}# #(f!,v!d,u,nn)# #(f!,v!d,u)# #(v!d,v!e,n,nnu)# #(v!d,v!e,n)# #(v!e,!0,nnun)# #(v!e,!0)# #{v!e,nnn,un,nn}# #{v!e,nnn,un}# #{v!d,o,u,nn}# #{v!d,o,u}# #(m!()1x1,v!e,w,n)# #(m!()1x1,v!e,w)# #(v!e,!0,nw)# #(v!e,!0)# #{v!e,nnnn,w,n}# #{v!e,nnnn,w}# #{v!e,nun,w,n}# #{v!e,nun,w}# #(v!φ,v!eg,b,-)# #(v!φ,v!eg,b)# #(v!eg,!0,b)# #(v!eg,!0)# #{v!eg,5n1a1n1b,b,-}# #{v!eg,5n1a1n1b,b}# #{v!eg,4n1b1n,b,-}# #{v!eg,4n1b1n,b}# #{v!eg,nnonb,b,-}# #{v!eg,nnonb,b}# #{v!φ,nnnn,-}# #{v!φ,nnnn}# #{v!φ,nnon,-}# #{v!φ,nnon}# #(end)#\n",
      "#(start)# #(v!q,m!()1x1,n,-)# #(v!q,m!()1x1,n)# #(m!()1x1,[n,w],n)# #(m!()1x1,[n,w])# #(m!()1x1,=,n,n)# #(m!()1x1,=,n)# #(=,-,n,nn)# #(=,-,n)# #(-,v!q,n,nnn)# #(-,v!q,n)# #(v!q,m!()1x1,n,nnnn)# #(v!q,m!()1x1,n)# #(m!()1x1,v!x,w,nnnnn)# #(m!()1x1,v!x,w)# #(v!x,!0,5n1w)# #(v!x,!0)# #(m!()1x1,-,w,n)# #(m!()1x1,-,w)# #(-,v!x,n,nw)# #(-,v!x,n)# #(v!x,!0,nwn)# #(v!x,!0)# #{v!x,nnnnw,wn,n}# #{v!x,nnnnw,wn}# #{-,nn,w,n}# #{-,nn,w}# #{m!()1x1,nnnn,n}# #{m!()1x1,nnnn}# #{v!q,nnnn,-}# #{v!q,nnnn}# #(end)#\n"
     ]
    }
   ],
   "source": [
    "! head -3 dataset-tangentl.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
